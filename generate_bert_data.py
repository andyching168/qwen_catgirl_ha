#!/usr/bin/env python3
"""
å¾ Qwen è¨“ç·´è³‡æ–™è½‰æ›æˆ BERT æ„åœ–åˆ†é¡æ ¼å¼

è¼¸å…¥ï¼štraining_data_v7_get_state.jsonl
è¼¸å‡ºï¼šbert_intent_train.jsonl, bert_intent_test.jsonl
"""

import json
import re
import random
from pathlib import Path
from collections import Counter

# æ„åœ–æ¨™ç±¤å°æ‡‰
INTENT_LABELS = {
    "turn_on": 0,
    "turn_off": 1,
    "climate_set_mode": 2,
    "get_state": 3,
    "chat": 4,  # æ²’æœ‰ ACTION çš„ç´”èŠå¤©
}

# ç”¨æ–¼çµ±è¨ˆ
stats = Counter()

def extract_action(assistant_response: str) -> str:
    """å¾åŠ©ç†å›æ‡‰ä¸­æå– ACTION åç¨±"""
    # å°‹æ‰¾ ACTION è¡Œ
    match = re.search(r'ACTION\s+(\w+)', assistant_response)
    if match:
        return match.group(1)
    return None

def extract_user_text(user_content: str) -> str:
    """æå–ç´”ç”¨æˆ¶è¼¸å…¥ï¼ˆç§»é™¤ 'User request:\n' å‰ç¶´ï¼‰
    
    Returns:
        ç”¨æˆ¶è¼¸å…¥æ–‡å­—ï¼Œå¦‚æœæ˜¯ç³»çµ±è¨Šæ¯å‰‡è¿”å› None
    """
    # è·³éäºŒæ¬¡å°è©±çš„ç³»çµ±è¨Šæ¯
    if user_content.startswith("State result:"):
        return None
    if user_content.startswith("Search result:"):
        return None
    
    if user_content.startswith("User request:\n"):
        return user_content[len("User request:\n"):].strip()
    return user_content.strip()

def process_jsonl(input_path: str, output_train: str, output_test: str, test_ratio: float = 0.1):
    """è™•ç† JSONL ä¸¦åˆ†å‰²æˆè¨“ç·´/æ¸¬è©¦é›†"""
    
    samples = []
    
    with open(input_path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            
            data = json.loads(line)
            messages = data.get('messages', [])
            
            # æ‰¾åˆ° user å’Œ assistant è¨Šæ¯
            user_msg = None
            assistant_msg = None
            
            for msg in messages:
                if msg['role'] == 'user':
                    user_msg = msg['content']
                elif msg['role'] == 'assistant':
                    assistant_msg = msg['content']
            
            if not user_msg or not assistant_msg:
                continue
            
            # æå–ç”¨æˆ¶è¼¸å…¥ï¼ˆéæ¿¾ç³»çµ±è¨Šæ¯ï¼‰
            text = extract_user_text(user_msg)
            if text is None:
                stats["skipped_system_msg"] += 1
                continue
            
            # æå– ACTION
            action = extract_action(assistant_msg)
            
            # åªä¿ç•™æˆ‘å€‘é—œå¿ƒçš„ 4 ç¨® ACTION + chat
            if action is None:
                label = INTENT_LABELS["chat"]
                stats["chat"] += 1
            elif action in INTENT_LABELS:
                label = INTENT_LABELS[action]
                stats[action] += 1
            else:
                # è·³éå…¶ä»– ACTIONï¼ˆå¦‚ search, light_set ç­‰ï¼‰
                stats[f"skipped_{action}"] += 1
                continue
            
            samples.append({
                "text": text,
                "label": label,
                "intent": action or "chat"
            })
    
    # æ‰“äº‚é †åº
    random.shuffle(samples)
    
    # åˆ†å‰²è¨“ç·´/æ¸¬è©¦
    split_idx = int(len(samples) * (1 - test_ratio))
    train_samples = samples[:split_idx]
    test_samples = samples[split_idx:]
    
    # å¯«å…¥æª”æ¡ˆ
    with open(output_train, 'w', encoding='utf-8') as f:
        for sample in train_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    with open(output_test, 'w', encoding='utf-8') as f:
        for sample in test_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    return len(train_samples), len(test_samples)

def add_chat_samples(output_train: str, output_test: str, num_samples: int = 500):
    """æ·»åŠ ç´”èŠå¤©æ¨£æœ¬ä»¥å¹³è¡¡è³‡æ–™"""
    
    chat_examples = [
        "ä½ å¥½",
        "å—¨",
        "æ—©å®‰",
        "åˆå®‰",
        "æ™šå®‰",
        "è¬è¬",
        "æ„Ÿè¬",
        "ä½ å«ä»€éº¼åå­—",
        "ä½ æ˜¯èª°",
        "ä½ å¥½å—",
        "ä»Šå¤©éå¾—å¥½å—",
        "åƒé£½äº†å—",
        "å¤©æ°£å¥½ç†±",
        "å¥½å†·å–”",
        "ç´¯æ­»äº†",
        "ç„¡èŠ",
        "é™ªæˆ‘èŠå¤©",
        "è¬›å€‹ç¬‘è©±",
        "èªªæ•…äº‹çµ¦æˆ‘è½",
        "ä½ å–œæ­¡ä»€éº¼",
        "ä½ æœƒåšä»€éº¼",
        "ä½ å²å®³å—",
        "æ™šé¤åƒä»€éº¼å¥½",
        "æ¨è–¦é›»å½±",
        "æœ‰ä»€éº¼å¥½ç©çš„",
        "æ˜å¤©è¦å¹¹å˜›",
        "æˆ‘å¥½ç´¯",
        "è‚šå­é¤“",
        "æƒ³ç¡è¦º",
        "ç¡ä¸è‘—",
        "åšæƒ¡å¤¢",
        "å¿ƒæƒ…ä¸å¥½",
        "é–‹å¿ƒ",
        "é›£é",
        "ç”Ÿæ°£",
        "ä½ çœŸå¯æ„›",
        "å–µå–µå–µ",
        "æ±ªæ±ªæ±ª",
        "å“ˆå“ˆå“ˆ",
        "å¥½ç¬‘",
        "ç„¡èŠæ­»äº†",
        "å¹«æˆ‘æŒ‰æ‘©",
        "æƒ³åƒé›¶é£Ÿ",
        "è¦å–æ°´",
        "å¥½æ¸´",
        "é€™æ˜¯ä»€éº¼",
        "ç‚ºä»€éº¼",
        "æ€éº¼è¾¦",
        "å¯ä»¥å—",
        "å¥½ä¸å¥½",
    ]
    
    # è®ŠåŒ–æ¨¡å¼
    variations = [
        "{text}",
        "{text}å–”",
        "{text}å•¦",
        "{text}å‘¢",
        "{text}å—",
        "æ¬¸{text}",
        "å–‚{text}",
        "å˜¿{text}",
    ]
    
    chat_samples = []
    for text in chat_examples:
        for var in variations:
            if "{text}" in var:
                chat_samples.append({
                    "text": var.format(text=text),
                    "label": INTENT_LABELS["chat"],
                    "intent": "chat"
                })
    
    random.shuffle(chat_samples)
    chat_samples = chat_samples[:num_samples]
    
    # åˆ†å‰²ä¸¦è¿½åŠ åˆ°æª”æ¡ˆ
    split_idx = int(len(chat_samples) * 0.9)
    train_chats = chat_samples[:split_idx]
    test_chats = chat_samples[split_idx:]
    
    with open(output_train, 'a', encoding='utf-8') as f:
        for sample in train_chats:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    with open(output_test, 'a', encoding='utf-8') as f:
        for sample in test_chats:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    return len(train_chats), len(test_chats)

def main():
    input_file = "generate_dataset/training_data_v7_get_state.jsonl"
    output_dir = Path("bert_training_data")
    output_dir.mkdir(exist_ok=True)
    
    output_train = output_dir / "intent_train.jsonl"
    output_test = output_dir / "intent_test.jsonl"
    
    print("=" * 60)
    print("BERT æ„åœ–åˆ†é¡è¨“ç·´è³‡æ–™ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # è½‰æ›ä¸»è¦è³‡æ–™
    print(f"\nğŸ“‚ è®€å–: {input_file}")
    train_count, test_count = process_jsonl(
        input_file,
        str(output_train),
        str(output_test)
    )
    
    print(f"\nğŸ“Š ACTION çµ±è¨ˆ:")
    for action, count in sorted(stats.items()):
        if action.startswith("skipped_"):
            print(f"   â­ï¸  {action}: {count} (è·³é)")
        else:
            print(f"   âœ… {action}: {count}")
    
    # æ·»åŠ èŠå¤©æ¨£æœ¬
    print(f"\nğŸ’¬ æ·»åŠ èŠå¤©æ¨£æœ¬...")
    chat_train, chat_test = add_chat_samples(str(output_train), str(output_test), 400)
    
    train_count += chat_train
    test_count += chat_test
    
    print(f"\nğŸ“ è¼¸å‡º:")
    print(f"   è¨“ç·´é›†: {output_train} ({train_count} ç­†)")
    print(f"   æ¸¬è©¦é›†: {output_test} ({test_count} ç­†)")
    
    # é¡¯ç¤ºæ¨™ç±¤å°æ‡‰
    print(f"\nğŸ·ï¸  æ¨™ç±¤å°æ‡‰:")
    for intent, label_id in INTENT_LABELS.items():
        print(f"   {label_id}: {intent}")
    
    print("\nâœ… å®Œæˆï¼")

if __name__ == "__main__":
    main()
